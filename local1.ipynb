{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA environment variable\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "CUDA Device Count: 1\n",
      "Current Device: 0\n",
      "Device Name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# cuda running??\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(f\"CUDA Device Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom ResNet model with added dropout and a fully connected layer\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V2)  # Load pre-trained ResNet101 model\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.model.fc.in_features, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Focal Loss function for handling class imbalance\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2, class_weights=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.class_weights = class_weights\n",
    "        self.ce = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        ce_loss = self.ce(logits, labels)  # Calculate cross-entropy loss\n",
    "        p_t = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * ce_loss  # Apply focal loss formula\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for loading lung images\n",
    "class LungImageDataset(Dataset):\n",
    "    def __init__(self, dataset_folder, transform=None):\n",
    "        self.dataset_folder = dataset_folder\n",
    "        self.transform = transform\n",
    "        self.data = self._load_data(dataset_folder)\n",
    "\n",
    "    def _load_data(self, dataset_folder):\n",
    "        # Load image paths and labels from the specified folder\n",
    "        data = []\n",
    "        labels = []\n",
    "        class_names = ['Pneumonia','Atelectasis', 'Cardiomegaly', 'Consolidation','Edema','Effusion', 'Emphysema','Fibrosis','Infiltration','Mass','Nodule','Pleural_Thickening','Pneumothorax', 'Normal', 'Hernia']\n",
    "        label_mapping = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "        for class_name, label in label_mapping.items():\n",
    "            class_folder = os.path.join(dataset_folder, class_name)\n",
    "            if os.path.isdir(class_folder):\n",
    "                for img_name in os.listdir(class_folder):\n",
    "                    img_path = os.path.join(class_folder, img_name)\n",
    "                    if os.path.isfile(img_path):\n",
    "                        data.append(img_path)\n",
    "                        labels.append(label)\n",
    "\n",
    "        print(f\"Loaded {len(data)} images from {dataset_folder}.\")\n",
    "        return list(zip(data, labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load an image and its label\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to aggregate model parameters from multiple clients\n",
    "def aggregate_model_params(global_model, clients):\n",
    "    global_dict = global_model.state_dict()\n",
    "    client_dicts = [client[2].state_dict() for client in clients]\n",
    "    total_data_points = sum(len(client[0].dataset) for client in clients)\n",
    "\n",
    "    for key in global_dict.keys():\n",
    "        weighted_sum = torch.zeros_like(global_dict[key], dtype=torch.float32)\n",
    "        for client_data, client_dict in zip(clients, client_dicts):\n",
    "            weight = len(client_data[0].dataset) / total_data_points\n",
    "            weighted_sum += client_dict[key].float() * weight\n",
    "        global_dict[key] = weighted_sum.type(global_dict[key].dtype)\n",
    "\n",
    "    global_model.load_state_dict(global_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_global_model(model, val_loader, criterion, device, num_classes):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    val_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "\n",
    "    # Final Tensor Concatenation\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "\n",
    "    # Metrics Calculation\n",
    "    accuracy = MulticlassAccuracy(num_classes=num_classes, average='macro')(all_preds, all_labels).item()\n",
    "    precision = MulticlassPrecision(num_classes=num_classes, average='macro')(all_preds, all_labels).item()\n",
    "    recall = MulticlassRecall(num_classes=num_classes, average='macro')(all_preds, all_labels).item()\n",
    "    f1 = MulticlassF1Score(num_classes=num_classes, average='macro')(all_preds, all_labels).item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    print(f\"Validation Loss: {val_loss:.4f} | Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1 Score: {f1:.4f}\")\n",
    "    return val_loss, accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform federated training\n",
    "def federated_train(global_model, criterion, clients, val_loader, device, num_classes, num_epochs=30):\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nFederated Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "        global_model.train()\n",
    "        epoch_client_losses = []\n",
    "        epoch_client_accuracies = []\n",
    "\n",
    "        for client_id, (client_data_loader, client_optimizer, client_model, client_scheduler) in enumerate(clients):\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "            client_model.to(device)\n",
    "            client_model.train()\n",
    "            running_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "\n",
    "            for images, labels in client_data_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                client_optimizer.zero_grad()\n",
    "                outputs = client_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                client_optimizer.step()\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "                total_train += labels.size(0)\n",
    "\n",
    "            client_loss = running_loss / total_train if total_train > 0 else 0.0\n",
    "            client_accuracy = correct_train / total_train if total_train > 0 else 0.0\n",
    "            epoch_client_losses.append(client_loss)\n",
    "            epoch_client_accuracies.append(client_accuracy)\n",
    "            print(f\"Client {client_id + 1}: Loss: {client_loss:.4f}, Accuracy: {client_accuracy:.4f}\")\n",
    "\n",
    "        avg_loss = np.mean(epoch_client_losses)\n",
    "        avg_accuracy = np.mean(epoch_client_accuracies)\n",
    "        print(f\"Average Client Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Average Client Accuracy: {avg_accuracy:.4f}\")\n",
    "        aggregate_model_params(global_model, clients)\n",
    "        val_loss, accuracy, precision, recall, f1 = validate_global_model(global_model, val_loader, criterion, device, num_classes)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(global_model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Saved the best model based on validation accuracy!\")\n",
    "\n",
    "    print(\"Training completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30994 images from C:\\Users\\Acer\\Desktop\\Model\\Dataset\\train.\n",
      "Loaded 6644 images from C:\\Users\\Acer\\Desktop\\Model\\Dataset\\val.\n",
      "Loaded 6652 images from C:\\Users\\Acer\\Desktop\\Model\\Dataset\\test.\n",
      "\n",
      "Federated Epoch [1/50]\n",
      "Client 1: Loss: 0.3811, Accuracy: 0.3317\n",
      "Client 2: Loss: 0.3800, Accuracy: 0.3215\n",
      "Client 3: Loss: 0.3710, Accuracy: 0.3325\n",
      "Average Client Loss: 0.3774\n",
      "Average Client Accuracy: 0.3286\n",
      "Validation Loss: 0.5694 | Accuracy: 0.1236 | Precision: 0.1239 | Recall: 0.1236 | F1 Score: 0.0882\n",
      "Saved the best model based on validation accuracy!\n",
      "\n",
      "Federated Epoch [2/50]\n",
      "Client 1: Loss: 0.3634, Accuracy: 0.3412\n",
      "Client 2: Loss: 0.3547, Accuracy: 0.3556\n",
      "Client 3: Loss: 0.3489, Accuracy: 0.3511\n",
      "Average Client Loss: 0.3557\n",
      "Average Client Accuracy: 0.3493\n",
      "Validation Loss: 0.4131 | Accuracy: 0.1699 | Precision: 0.1792 | Recall: 0.1699 | F1 Score: 0.1581\n",
      "Saved the best model based on validation accuracy!\n",
      "\n",
      "Federated Epoch [3/50]\n",
      "Client 1: Loss: 0.3440, Accuracy: 0.3621\n",
      "Client 2: Loss: 0.3378, Accuracy: 0.3733\n",
      "Client 3: Loss: 0.3348, Accuracy: 0.3763\n",
      "Average Client Loss: 0.3389\n",
      "Average Client Accuracy: 0.3706\n",
      "Validation Loss: 0.3719 | Accuracy: 0.2085 | Precision: 0.2693 | Recall: 0.2085 | F1 Score: 0.1905\n",
      "Saved the best model based on validation accuracy!\n",
      "\n",
      "Federated Epoch [4/50]\n",
      "Client 1: Loss: 0.3318, Accuracy: 0.3785\n",
      "Client 2: Loss: 0.3263, Accuracy: 0.3758\n",
      "Client 3: Loss: 0.3238, Accuracy: 0.3759\n",
      "Average Client Loss: 0.3273\n",
      "Average Client Accuracy: 0.3767\n",
      "Validation Loss: 0.3417 | Accuracy: 0.1993 | Precision: 0.3076 | Recall: 0.1993 | F1 Score: 0.1958\n",
      "\n",
      "Federated Epoch [5/50]\n",
      "Client 1: Loss: 0.3216, Accuracy: 0.3800\n",
      "Client 2: Loss: 0.3130, Accuracy: 0.3955\n",
      "Client 3: Loss: 0.3100, Accuracy: 0.3935\n",
      "Average Client Loss: 0.3148\n",
      "Average Client Accuracy: 0.3897\n",
      "Validation Loss: 0.3225 | Accuracy: 0.2171 | Precision: 0.2816 | Recall: 0.2171 | F1 Score: 0.2229\n",
      "Saved the best model based on validation accuracy!\n",
      "\n",
      "Federated Epoch [6/50]\n",
      "Client 1: Loss: 0.3103, Accuracy: 0.3964\n",
      "Client 2: Loss: 0.3082, Accuracy: 0.3981\n",
      "Client 3: Loss: 0.3023, Accuracy: 0.4038\n",
      "Average Client Loss: 0.3069\n",
      "Average Client Accuracy: 0.3994\n",
      "Validation Loss: 0.3150 | Accuracy: 0.2327 | Precision: 0.3080 | Recall: 0.2327 | F1 Score: 0.2325\n",
      "Saved the best model based on validation accuracy!\n",
      "\n",
      "Federated Epoch [7/50]\n",
      "Client 1: Loss: 0.3029, Accuracy: 0.4011\n",
      "Client 2: Loss: 0.2980, Accuracy: 0.4106\n",
      "Client 3: Loss: 0.2953, Accuracy: 0.4121\n",
      "Average Client Loss: 0.2988\n",
      "Average Client Accuracy: 0.4079\n",
      "Validation Loss: 0.3091 | Accuracy: 0.2516 | Precision: 0.3249 | Recall: 0.2516 | F1 Score: 0.2494\n",
      "Saved the best model based on validation accuracy!\n",
      "\n",
      "Federated Epoch [8/50]\n",
      "Client 1: Loss: 0.2957, Accuracy: 0.4117\n",
      "Client 2: Loss: 0.2943, Accuracy: 0.4173\n",
      "Client 3: Loss: 0.2877, Accuracy: 0.4237\n",
      "Average Client Loss: 0.2926\n",
      "Average Client Accuracy: 0.4175\n",
      "Validation Loss: 0.3070 | Accuracy: 0.2516 | Precision: 0.3643 | Recall: 0.2516 | F1 Score: 0.2569\n",
      "\n",
      "Federated Epoch [9/50]\n",
      "Client 1: Loss: 0.2900, Accuracy: 0.4185\n",
      "Client 2: Loss: 0.2884, Accuracy: 0.4238\n",
      "Client 3: Loss: 0.2806, Accuracy: 0.4306\n",
      "Average Client Loss: 0.2863\n",
      "Average Client Accuracy: 0.4243\n",
      "Validation Loss: 0.3105 | Accuracy: 0.2649 | Precision: 0.3289 | Recall: 0.2649 | F1 Score: 0.2637\n",
      "Saved the best model based on validation accuracy!\n",
      "\n",
      "Federated Epoch [10/50]\n",
      "Client 1: Loss: 0.2844, Accuracy: 0.4306\n",
      "Client 2: Loss: 0.2811, Accuracy: 0.4298\n",
      "Client 3: Loss: 0.2745, Accuracy: 0.4290\n",
      "Average Client Loss: 0.2800\n",
      "Average Client Accuracy: 0.4298\n",
      "Validation Loss: 0.3005 | Accuracy: 0.2770 | Precision: 0.4185 | Recall: 0.2770 | F1 Score: 0.2753\n",
      "Saved the best model based on validation accuracy!\n",
      "\n",
      "Federated Epoch [11/50]\n",
      "Client 1: Loss: 0.2806, Accuracy: 0.4333\n"
     ]
    }
   ],
   "source": [
    "# Main function to load data and start federated training\n",
    "def main():\n",
    "    train_folder = \"C:\\\\Users\\\\Acer\\\\Desktop\\\\Model\\\\Dataset\\\\train\"\n",
    "    val_folder = \"C:\\\\Users\\\\Acer\\\\Desktop\\\\Model\\\\Dataset\\\\val\"\n",
    "    test_folder = \"C:\\\\Users\\\\Acer\\\\Desktop\\\\Model\\\\Dataset\\\\test\"\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    val_test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dataset = LungImageDataset(dataset_folder=train_folder, transform=train_transform)\n",
    "    val_dataset = LungImageDataset(dataset_folder=val_folder, transform=val_test_transform)\n",
    "    test_dataset = LungImageDataset(dataset_folder=test_folder, transform=val_test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    num_classes = 15\n",
    "    global_model = CustomResNet(num_classes=num_classes).to(device)\n",
    "    class_weights_tensor = torch.ones(num_classes, dtype=torch.float32).to(device)\n",
    "    criterion = FocalLoss(class_weights=class_weights_tensor)\n",
    "\n",
    "    num_clients = 3\n",
    "    clients = []\n",
    "    for i in range(num_clients):\n",
    "        client_model = CustomResNet(num_classes=num_classes)\n",
    "        client_optimizer = optim.Adam(client_model.parameters(), lr=0.001)\n",
    "        client_scheduler = optim.lr_scheduler.StepLR(client_optimizer, step_size=5, gamma=0.1)\n",
    "        client_loader, _ = random_split(train_dataset, [len(train_dataset) // num_clients, len(train_dataset) - (len(train_dataset) // num_clients)])\n",
    "        client_loader = DataLoader(client_loader, batch_size=32, shuffle=True)\n",
    "        clients.append((client_loader, client_optimizer, client_model, client_scheduler))\n",
    "\n",
    "    federated_train(global_model, criterion, clients, val_loader, device, num_classes, num_epochs=50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
